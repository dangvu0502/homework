{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Setup Project and Web Application Boilerplate",
        "description": "Initialize the project repository. Set up a basic frontend web application structure using a modern framework (e.g., React, Vue) and a backend stub for future API integration.",
        "details": "Includes installing dependencies, configuring build tools (like Vite or Webpack), and creating the initial file structure for components, services, and styles.",
        "testStrategy": "Verify that the development server runs and a basic 'Hello World' page is displayed in the browser. The repository should be created on a version control system.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement Image Upload and Display Component",
        "description": "Create a UI component that allows users to select a local image file. The selected image should be rendered onto a canvas element in the application.",
        "details": "Handle different image file types (JPG, PNG). Ensure the image is displayed correctly within the canvas area, potentially with scaling.",
        "testStrategy": "Manually test by uploading various images. Verify the image appears correctly on the canvas. Check for error handling with invalid file types.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Implement Bounding Box Drawing Functionality",
        "description": "Enable users to draw rectangular bounding boxes over the displayed image using mouse interactions (click-and-drag).",
        "details": "Capture mouse down, mouse move, and mouse up events on the canvas to draw a rectangle. Store the coordinates of each drawn box in the application's state.",
        "testStrategy": "Manually draw several boxes on an uploaded image. Verify that the boxes are drawn accurately and their coordinates are stored correctly.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Implement Tag Assignment for Bounding Boxes",
        "description": "After a bounding box is drawn, provide a mechanism for the user to assign a predefined tag (Button, Input, Radio, Dropdown) to it.",
        "details": "A dropdown menu or a modal could appear after drawing a box. The list of drawn boxes and their tags should be displayed on the side for review.",
        "testStrategy": "Draw a box, assign a tag from the list, and verify it's associated correctly. Test editing or deleting a box/tag. Ensure the state reflects all changes.",
        "priority": "high",
        "dependencies": [
          3
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Implement 'Save' Functionality for Ground Truth",
        "description": "Create a 'Save' button that exports the list of bounding boxes and their assigned tags into a structured JSON file, which the user can download.",
        "details": "The JSON format should be well-defined, containing the image name, and a list of objects, each with coordinates (e.g., x, y, width, height) and a label.",
        "testStrategy": "Label an image with several boxes, click 'Save', and inspect the downloaded JSON file to ensure it matches the expected format and contains the correct data.",
        "priority": "medium",
        "dependencies": [
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Create Backend Service to Call LLM API",
        "description": "Develop a simple backend API endpoint that accepts an image, forwards it to a multimodal LLM for UI element detection, and returns the predicted bounding boxes and tags.",
        "details": "This service acts as a proxy to securely handle the LLM API key. It will need to parse the LLM's response into the same JSON format used for ground truth. The LLM should be prompted to only identify 'Button', 'Input', 'Radio', and 'Dropdown'.",
        "testStrategy": "Test the endpoint directly using a tool like Postman or cURL. Send an image and verify that it returns a JSON response with predicted annotations in the correct format.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Integrate 'Predict' Button in UI",
        "description": "Add a 'Predict' button to the UI. On click, it will call the backend service with the uploaded image and display the LLM-predicted boxes and tags on the canvas.",
        "details": "Predicted boxes should be displayed in a different color to distinguish them from user-drawn ground truth boxes. The results should be savable in the same JSON format.",
        "testStrategy": "Upload an image, click 'Predict', and verify that the predicted boxes are fetched from the backend and rendered correctly on the canvas. Check the network tab to ensure the API call is successful.",
        "priority": "medium",
        "dependencies": [
          2,
          6
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Develop Evaluation Script: Data Parsing and Box Matching",
        "description": "Create the initial structure of the command-line evaluation script. It should parse a directory of ground truth JSON files and a directory of prediction JSON files and match predicted boxes to ground truth boxes.",
        "details": "Matching will be based on Intersection over Union (IoU) with a certain threshold (e.g., 0.5). A predicted box is a match if its IoU with a ground truth box is above the threshold and the labels are the same.",
        "testStrategy": "Create sample ground truth and prediction JSON files. Run the script and manually verify that it correctly identifies true positives, false positives, and false negatives.",
        "priority": "high",
        "dependencies": [
          5,
          7
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Performance Metrics Calculation in Script",
        "description": "Extend the evaluation script to calculate precision, recall, and F1-score for each of the four specified tags (Button, Input, Radio, Dropdown) based on the matching results.",
        "details": "Precision = TP / (TP + FP). Recall = TP / (TP + FN). F1-score = 2 * (Precision * Recall) / (Precision + Recall). Handle division-by-zero cases.",
        "testStrategy": "Using sample files with known counts, manually calculate the expected metrics and compare them against the script's output to ensure correctness.",
        "priority": "high",
        "dependencies": [
          8
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Finalize CLI Tool and Project Documentation",
        "description": "Refine the evaluation script into a user-friendly command-line tool that accepts folder paths as arguments. Create a comprehensive README.md file for the entire project.",
        "details": "The README should explain the project's purpose, how to set up the environment, how to run the web app, and how to use the evaluation tool with example commands.",
        "testStrategy": "Run the CLI tool from the command line with test folders. Check that the output is well-formatted. Review the README for clarity, completeness, and accuracy.",
        "priority": "medium",
        "dependencies": [
          5,
          7,
          9
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Add Front-End Tests for Main Annotation Flows",
        "description": "Create component tests that cover the critical user flows: uploading an image, drawing bounding boxes, assigning tags, and exporting annotations.",
        "details": "Write tests with Vitest + React Testing Library for:\n1. FileUpload – upload preview and handler call\n2. AnnotationCanvas – drawing rectangles & storing/rendering box\n3. TagSelector – switching current tag\n4. ExportControls – generating & downloading JSON\nThis will provide confidence the primary user journey works.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          1,
          2,
          3,
          4,
          5
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Component tests for FileUpload (upload image)",
            "description": "Ensure selecting a file updates preview and calls onFileSelect.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 2,
            "title": "Component tests for AnnotationCanvas (draw boxes)",
            "description": "Test that drawing rectangle stores bounding box and renders it.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 3,
            "title": "Component tests for TagSelector (assign tag)",
            "description": "Verify tag selection updates selectedTag state.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          },
          {
            "id": 4,
            "title": "Component tests for ExportControls (save JSON)",
            "description": "Test JSON export downloads expected content.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 11
          }
        ]
      },
      {
        "id": 12,
        "title": "Implement Scalability and Performance Optimizations",
        "description": "Add support for scaling the annotation tool UI and backend to handle larger images, more concurrent users, and higher annotation throughput. This includes optimizing image processing, frontend rendering, and backend API load capacity.",
        "details": "This task involves a multi-faceted approach to performance. For the frontend, investigate using Web Workers to offload image processing from the main thread, preventing UI freezes when loading large images. Implement canvas virtualization or tiling to only render the visible portion of a large image, improving interaction performance. For the backend, the API endpoint from Task 6 must be hardened. Implement a request queue to manage concurrent calls to the LLM and consider introducing a caching layer (e.g., Redis) to store and retrieve results for previously processed images, reducing latency and cost. The data transfer between client and server should also be optimized by implementing client-side image compression before upload.",
        "testStrategy": "Frontend performance will be verified by profiling the application in browser developer tools while uploading and annotating a very large image (e.g., >10MB, 8K resolution). The UI must remain responsive. Automated tests using a framework like Playwright can be added to measure frame rates during drawing actions. For the backend, use a load testing tool like k6 or JMeter to simulate at least 50 concurrent users making requests to the '/predict' endpoint. The test should measure the average response time, error rate, and requests per second. The P95 latency should remain under a predefined threshold (e.g., 2 seconds).",
        "status": "pending",
        "dependencies": [
          2,
          3,
          6,
          7,
          11
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Implement Multi-Image Upload and Annotation Workflow",
        "description": "Enhance the frontend to support uploading multiple images simultaneously. Implement a gallery view for easy navigation and ensure the existing annotation tools work seamlessly across a batch of images.",
        "details": "Update the image upload component from Task 2 to accept multiple files by adding the 'multiple' attribute to the file input element. Create a new UI component, such as a scrollable thumbnail gallery or list, to display all uploaded images. Implement state management to hold an array of image objects, where each object contains the image data and its corresponding annotations. Clicking a thumbnail in the gallery should set it as the active image in the main annotation canvas, loading its specific annotations. When switching images, the state of the previous image's annotations must be preserved. The 'Save' functionality from Task 5 needs to be adapted to export all annotations for all images in the batch, likely into a single structured JSON file that contains an array of objects, one for each annotated image.",
        "testStrategy": "Manually test by selecting 5+ images in the file dialog and confirming they all appear in the gallery view. Annotate image 1, switch to image 3, and add an annotation there. Switch back to image 1 and verify its annotations are still present. Finally, use the 'Save' button and inspect the downloaded JSON to ensure it contains the correct, separate annotation data for both image 1 and image 3. Extend the automated tests from Task 11 to cover the multi-upload scenario, including simulating the selection of multiple files and verifying the application state updates correctly. Add component tests for the new image gallery to check rendering and selection logic.",
        "status": "pending",
        "dependencies": [
          2,
          5,
          11,
          12
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Enable Multi-File Upload and Refactor State Management",
            "description": "Modify the existing file upload component to accept multiple image files simultaneously. Refactor the application's state management to handle an array of image objects, where each object will store the image data, a unique ID, and an empty array for its future annotations.",
            "dependencies": [],
            "details": "Locate the file input element from Task 2 and add the `multiple` attribute. Update the file handling logic to process a `FileList` object instead of a single file. Iterate through the `FileList`, creating a new object for each image containing properties like `id` (e.g., using a simple counter or UUID), `imageData` (e.g., a data URL from FileReader), and `annotations` (initialized as an empty array). Store this array of image objects in the main application state (e.g., using React's useState, Redux, or a similar state management library). The first image in the list should be set as the default active image.",
            "status": "pending",
            "testStrategy": "Open the file dialog and verify that you can select multiple image files (e.g., 3-5 images). After selection, use browser developer tools to inspect the application's state and confirm it contains an array of objects, with each object corresponding to an uploaded image and having the correct structure."
          },
          {
            "id": 2,
            "title": "Create a Scrollable Thumbnail Gallery Component",
            "description": "Develop a new UI component that displays a gallery of thumbnails for all uploaded images. This gallery should be visually distinct from the main annotation canvas and allow users to see the entire batch of images they are working on.",
            "dependencies": [
              "13.1"
            ],
            "details": "Create a new component (e.g., `ImageGallery.js`). This component will receive the array of image objects from the application state as a prop. It should map over this array and render a thumbnail for each image. Use CSS to style this into a horizontal, scrollable list, possibly located below or to the side of the main canvas. Each thumbnail can be a simple `<img>` tag with its `src` set to the `imageData` URL. For performance, consider rendering thumbnails at a fixed, smaller size (e.g., 100x100 pixels) to avoid using full-resolution images.",
            "status": "pending",
            "testStrategy": "After uploading multiple images, verify that the new gallery component appears and correctly displays a thumbnail for every uploaded image. Test the scrolling behavior if the number of images exceeds the visible area of the gallery."
          },
          {
            "id": 3,
            "title": "Implement Active Image Switching Logic",
            "description": "Enable users to select an image from the thumbnail gallery, which will then be displayed as the 'active' image in the main annotation canvas. The currently active thumbnail should be visually highlighted.",
            "dependencies": [
              "13.1",
              "13.2"
            ],
            "details": "Introduce a new piece of state, `activeImageId`, to store the ID of the currently selected image. Add an `onClick` handler to each thumbnail in the gallery component. When a thumbnail is clicked, this handler should update the `activeImageId` in the global state. The main annotation canvas component should be modified to read this `activeImageId`, find the corresponding image object in the state array, and render its `imageData`. Apply a distinct style (e.g., a colored border or different opacity) to the thumbnail in the gallery whose ID matches the `activeImageId`.",
            "status": "pending",
            "testStrategy": "Upload a set of images. Click on the third thumbnail in the gallery. Verify that the main canvas updates to show the third image and that the third thumbnail is now visually highlighted. Click on another thumbnail and confirm the canvas and highlight update accordingly."
          },
          {
            "id": 4,
            "title": "Integrate Per-Image Annotation State",
            "description": "Connect the existing annotation tools to work on the currently active image. Ensure that annotations are saved to the correct image's object in the state when the user switches to a different image.",
            "dependencies": [
              "13.3"
            ],
            "details": "Modify the annotation logic (from Tasks 3 & 4) to read from and write to the `annotations` array of the active image object. When the `activeImageId` changes, the annotation canvas should clear any existing drawings and render the annotations from the newly selected image's `annotations` array. Any new annotations (drawing boxes, assigning tags) should be pushed into this specific array. The state of annotations for non-active images must be preserved untouched within their respective objects in the main state array.",
            "status": "pending",
            "testStrategy": "Upload three images. Select Image 1 and draw two bounding boxes. Select Image 3 and draw one bounding box. Switch back to Image 1 and verify that the original two boxes are still present. Switch to Image 2 (which has not been annotated) and confirm the canvas is empty. Finally, switch back to Image 3 and verify its single box is displayed correctly."
          },
          {
            "id": 5,
            "title": "Update 'Save' Functionality to Export All Annotations",
            "description": "Adapt the 'Save' functionality (from Task 5) to export the annotations for all uploaded images into a single, structured JSON file.",
            "dependencies": [
              "13.4"
            ],
            "details": "Modify the `onClick` handler for the 'Save' button. Instead of just exporting the annotations for the active image, the new logic should process the entire array of image objects from the state. The output JSON file should have a root key (e.g., `projectAnnotations`) containing an array. Each element in this array will be an object representing one image, containing its name or ID and its corresponding `annotations` array. This creates a complete ground truth file for the entire batch.",
            "status": "pending",
            "testStrategy": "Annotate several images in a batch. Click the 'Save' button. Inspect the downloaded JSON file. Verify that it contains a top-level array with an entry for each image that was annotated. Check that the annotations within each entry are correct and match what was drawn on the canvas for that specific image."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-07-17T02:10:01.354Z",
      "updated": "2025-07-21T04:43:47.779Z",
      "description": "Tasks for master context"
    }
  }
}